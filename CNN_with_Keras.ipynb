{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_with_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1E0fMwjF0fTZbjjDpu5SW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuzaifadev/IBM-AI-Engineering/blob/master/CNN_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa92S2FBEzQs",
        "colab_type": "text"
      },
      "source": [
        "# **Convolutional Neural Networks with Keras**\n",
        "\n",
        "In deep learning, a convolutional neural network is a class of deep neural networks, most commonly applied to analyzing visual imagery. This notebook is representing the foundational structure of using CNN with Keras.\n",
        "\n",
        "By [Muhammad Huzaifa Shahbaz](https://www.linkedin.com/in/mhuzaifadev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7T7rALyE_FQ",
        "colab_type": "text"
      },
      "source": [
        "## **Importing Keras and Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sMKPGNWEqdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37bd7e5d-95a1-42d7-b88c-08d790139144"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
        "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
        "from keras.layers import Flatten # to flatten data for fully connected layers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2EwLKI7FQAg",
        "colab_type": "text"
      },
      "source": [
        "### **Convolutional Layer with One set of convolutional and pooling layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJmXRSnKFZGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "35a3ab0e-7eb3-4919-d5f2-70ca39913348"
      },
      "source": [
        "# import data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LCnPRzwFhCt",
        "colab_type": "text"
      },
      "source": [
        "Normalizing the pixel values to be between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhRADVB9Fl3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXgO32-5Fo-m",
        "colab_type": "text"
      },
      "source": [
        "Coverting target variables into binary categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wktXVV38FuMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdF1R2SHF0r4",
        "colab_type": "text"
      },
      "source": [
        "## **Building a Neural Network**\n",
        "\n",
        "Defining a function that creates our model. Starting with one set of convolutional and pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niASyh5xF-qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_model():\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V257qNoGCoF",
        "colab_type": "text"
      },
      "source": [
        "## **Training the Model & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEpYidU5GS_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "7cae5e8e-9792-4ac2-b75d-f34454c40ebb"
      },
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 19s - loss: 0.2977 - accuracy: 0.9139 - val_loss: 0.1123 - val_accuracy: 0.9685\n",
            "Epoch 2/10\n",
            " - 18s - loss: 0.0877 - accuracy: 0.9744 - val_loss: 0.0630 - val_accuracy: 0.9817\n",
            "Epoch 3/10\n",
            " - 18s - loss: 0.0582 - accuracy: 0.9828 - val_loss: 0.0559 - val_accuracy: 0.9816\n",
            "Epoch 4/10\n",
            " - 18s - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.0451 - val_accuracy: 0.9857\n",
            "Epoch 5/10\n",
            " - 18s - loss: 0.0358 - accuracy: 0.9892 - val_loss: 0.0368 - val_accuracy: 0.9885\n",
            "Epoch 6/10\n",
            " - 18s - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.0373 - val_accuracy: 0.9880\n",
            "Epoch 7/10\n",
            " - 18s - loss: 0.0238 - accuracy: 0.9930 - val_loss: 0.0429 - val_accuracy: 0.9871\n",
            "Epoch 8/10\n",
            " - 18s - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.0330 - val_accuracy: 0.9887\n",
            "Epoch 9/10\n",
            " - 18s - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0424 - val_accuracy: 0.9870\n",
            "Epoch 10/10\n",
            " - 18s - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0386 - val_accuracy: 0.9878\n",
            "Accuracy: 0.9878000020980835 \n",
            " Error: 1.2199997901916504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XDLzafiHD23",
        "colab_type": "text"
      },
      "source": [
        "### **Convolutional Layer with two sets of convolutional and pooling layers**\n",
        "\n",
        "**Building a neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOaMzyohHKeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_model():\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTLQwkOTHVfv",
        "colab_type": "text"
      },
      "source": [
        "**Training the Model & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0NYjVJNHleV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "eb10deec-c507-47fa-8934-73ec288e69d1"
      },
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 19s - loss: 0.4653 - accuracy: 0.8694 - val_loss: 0.1315 - val_accuracy: 0.9618\n",
            "Epoch 2/10\n",
            " - 19s - loss: 0.1184 - accuracy: 0.9652 - val_loss: 0.0819 - val_accuracy: 0.9749\n",
            "Epoch 3/10\n",
            " - 19s - loss: 0.0847 - accuracy: 0.9746 - val_loss: 0.0622 - val_accuracy: 0.9814\n",
            "Epoch 4/10\n",
            " - 19s - loss: 0.0691 - accuracy: 0.9794 - val_loss: 0.0557 - val_accuracy: 0.9820\n",
            "Epoch 5/10\n",
            " - 19s - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.0490 - val_accuracy: 0.9848\n",
            "Epoch 6/10\n",
            " - 19s - loss: 0.0513 - accuracy: 0.9847 - val_loss: 0.0477 - val_accuracy: 0.9858\n",
            "Epoch 7/10\n",
            " - 19s - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.0456 - val_accuracy: 0.9857\n",
            "Epoch 8/10\n",
            " - 19s - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0470 - val_accuracy: 0.9854\n",
            "Epoch 9/10\n",
            " - 19s - loss: 0.0376 - accuracy: 0.9883 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
            "Epoch 10/10\n",
            " - 19s - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0369 - val_accuracy: 0.9883\n",
            "Accuracy: 0.9883000254631042 \n",
            " Error: 1.1699974536895752\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}