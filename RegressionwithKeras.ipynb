{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegressionwithKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtWQ7L0AImP2nHkoCUUKRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuzaifadev/IBM-AI-Engineering/blob/master/RegressionwithKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPpfTgGnuAj8",
        "colab_type": "text"
      },
      "source": [
        "# **Linear Regression using Keras**\n",
        "\n",
        "Linear regression is a common Statistical Data Analysis technique. It is used to determine the extent to which there is a linear relationship between a dependent variable and one or more independent variables.\n",
        "\n",
        "We have implemented here using keras and concrete_data.csv\n",
        "\n",
        "By [Muhammad Huzaifa Shahbaz](https://www.linkedin.com/in/mhuzaifadev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HLNzRpZu52Q",
        "colab_type": "text"
      },
      "source": [
        "## **Importing Libraries**\n",
        "\n",
        "We will import NumPy library as np, Pandas as pd, Sequential{} from keras.models and Dense{} from keras.layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnIoVKfZTCn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9HcdIxxuxHx",
        "colab_type": "text"
      },
      "source": [
        "##**DataFraming**\n",
        "\n",
        "Reading .csv data into a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb27wS3fqGw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "331ae6fe-f6de-4843-a59b-72bfc8fd6441"
      },
      "source": [
        "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
        "concrete_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  ...  Fine Aggregate  Age  Strength\n",
              "0   540.0                 0.0      0.0  ...           676.0   28     79.99\n",
              "1   540.0                 0.0      0.0  ...           676.0   28     61.89\n",
              "2   332.5               142.5      0.0  ...           594.0  270     40.27\n",
              "3   332.5               142.5      0.0  ...           594.0  365     41.05\n",
              "4   198.6               132.4      0.0  ...           825.5  360     44.30\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziWwSTz9vUKz",
        "colab_type": "text"
      },
      "source": [
        "## **Cleaning Data**\n",
        "\n",
        "Data Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7frVhTcMqJ61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b616fcac-839e-4e6b-96d7-0b23d1e93cf3"
      },
      "source": [
        "concrete_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1030, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8FpsPOYvg1B",
        "colab_type": "text"
      },
      "source": [
        "So, there are approximately 1000 samples to train our model on. Because of the few samples, we have to be careful not to overfit the training data.\n",
        "\n",
        "Let's check the dataset for any missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUWM6_8SqNL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4815e250-2319-406f-a0ce-d519463a1ca4"
      },
      "source": [
        "concrete_data.describe()\n",
        "concrete_data.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement                0\n",
              "Blast Furnace Slag    0\n",
              "Fly Ash               0\n",
              "Water                 0\n",
              "Superplasticizer      0\n",
              "Coarse Aggregate      0\n",
              "Fine Aggregate        0\n",
              "Age                   0\n",
              "Strength              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcPvlZwPqSqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concrete_data_columns = concrete_data.columns\n",
        "\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
        "target = concrete_data['Strength'] # Strength column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mZQGVsTqS49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2b48ac85-b276-4be0-a02e-3554039e3c16"
      },
      "source": [
        "predictors.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  ...  Coarse Aggregate  Fine Aggregate  Age\n",
              "0   540.0                 0.0      0.0  ...            1040.0           676.0   28\n",
              "1   540.0                 0.0      0.0  ...            1055.0           676.0   28\n",
              "2   332.5               142.5      0.0  ...             932.0           594.0  270\n",
              "3   332.5               142.5      0.0  ...             932.0           594.0  365\n",
              "4   198.6               132.4      0.0  ...             978.4           825.5  360\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NteQekkpqauF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "eb556a9d-b48e-4157-8cdd-45ba9d5972c9"
      },
      "source": [
        "target.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    79.99\n",
              "1    61.89\n",
              "2    40.27\n",
              "3    41.05\n",
              "4    44.30\n",
              "Name: Strength, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvyImM6swHDt",
        "colab_type": "text"
      },
      "source": [
        "Normalizing the data by substracting the mean and dividing by the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIXrMRgTqvnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a22688cf-8b13-4ba0-9fcd-f1125133626a"
      },
      "source": [
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
        "predictors_norm.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Cement  Blast Furnace Slag  ...  Fine Aggregate       Age\n",
              "0  2.476712           -0.856472  ...       -1.217079 -0.279597\n",
              "1  2.476712           -0.856472  ...       -1.217079 -0.279597\n",
              "2  0.491187            0.795140  ...       -2.239829  3.551340\n",
              "3  0.491187            0.795140  ...       -2.239829  5.055221\n",
              "4 -0.790075            0.678079  ...        0.647569  4.976069\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29DY8dTSqvwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_cols = predictors_norm.shape[1] # number of predictors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai6pW-d9wQoD",
        "colab_type": "text"
      },
      "source": [
        "## **Building a Neural Network**\n",
        "\n",
        "Defining a function that defines our regression model for us so that we can conveniently call it to create our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPxtKpdCqv4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define regression model\n",
        "def regression_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCQ5EddUUuLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "model = regression_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKW7SaQyxEG_",
        "colab_type": "text"
      },
      "source": [
        "## **Train and test the Neural Network**\n",
        "\n",
        "we will train and test the model at the same time using the fit method. We will leave out 30% of the data for validation and we will train the model for 250 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjJNVTLyUxzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d275e50c-abaf-4a16-d40b-c65271a128a3"
      },
      "source": [
        "# fit the model\n",
        "model.fit(predictors_norm, target, validation_split=0.3, epochs=250, verbose=2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 721 samples, validate on 309 samples\n",
            "Epoch 1/250\n",
            " - 0s - loss: 9.6792 - val_loss: 90.9219\n",
            "Epoch 2/250\n",
            " - 0s - loss: 9.0791 - val_loss: 93.2151\n",
            "Epoch 3/250\n",
            " - 0s - loss: 9.1407 - val_loss: 96.4908\n",
            "Epoch 4/250\n",
            " - 0s - loss: 9.4566 - val_loss: 85.7645\n",
            "Epoch 5/250\n",
            " - 0s - loss: 9.0421 - val_loss: 87.3612\n",
            "Epoch 6/250\n",
            " - 0s - loss: 8.5146 - val_loss: 88.7310\n",
            "Epoch 7/250\n",
            " - 0s - loss: 8.7531 - val_loss: 87.7249\n",
            "Epoch 8/250\n",
            " - 0s - loss: 8.8220 - val_loss: 85.0742\n",
            "Epoch 9/250\n",
            " - 0s - loss: 8.7036 - val_loss: 92.9390\n",
            "Epoch 10/250\n",
            " - 0s - loss: 8.7434 - val_loss: 91.8916\n",
            "Epoch 11/250\n",
            " - 0s - loss: 8.6369 - val_loss: 90.3870\n",
            "Epoch 12/250\n",
            " - 0s - loss: 8.9282 - val_loss: 77.7300\n",
            "Epoch 13/250\n",
            " - 0s - loss: 9.4286 - val_loss: 93.4739\n",
            "Epoch 14/250\n",
            " - 0s - loss: 9.1417 - val_loss: 84.8057\n",
            "Epoch 15/250\n",
            " - 0s - loss: 9.1122 - val_loss: 88.3719\n",
            "Epoch 16/250\n",
            " - 0s - loss: 8.4834 - val_loss: 93.2775\n",
            "Epoch 17/250\n",
            " - 0s - loss: 9.2937 - val_loss: 90.6500\n",
            "Epoch 18/250\n",
            " - 0s - loss: 8.4113 - val_loss: 94.0229\n",
            "Epoch 19/250\n",
            " - 0s - loss: 9.0401 - val_loss: 93.2982\n",
            "Epoch 20/250\n",
            " - 0s - loss: 8.7256 - val_loss: 87.7625\n",
            "Epoch 21/250\n",
            " - 0s - loss: 8.6472 - val_loss: 82.9306\n",
            "Epoch 22/250\n",
            " - 0s - loss: 8.9406 - val_loss: 84.9127\n",
            "Epoch 23/250\n",
            " - 0s - loss: 8.6499 - val_loss: 93.9700\n",
            "Epoch 24/250\n",
            " - 0s - loss: 8.8784 - val_loss: 83.3807\n",
            "Epoch 25/250\n",
            " - 0s - loss: 9.1751 - val_loss: 90.8558\n",
            "Epoch 26/250\n",
            " - 0s - loss: 8.6037 - val_loss: 94.1184\n",
            "Epoch 27/250\n",
            " - 0s - loss: 8.5444 - val_loss: 89.4512\n",
            "Epoch 28/250\n",
            " - 0s - loss: 8.6769 - val_loss: 86.4314\n",
            "Epoch 29/250\n",
            " - 0s - loss: 8.9190 - val_loss: 88.3874\n",
            "Epoch 30/250\n",
            " - 0s - loss: 8.5172 - val_loss: 89.8787\n",
            "Epoch 31/250\n",
            " - 0s - loss: 8.7217 - val_loss: 86.4041\n",
            "Epoch 32/250\n",
            " - 0s - loss: 8.7812 - val_loss: 87.3754\n",
            "Epoch 33/250\n",
            " - 0s - loss: 8.6862 - val_loss: 78.7684\n",
            "Epoch 34/250\n",
            " - 0s - loss: 8.8716 - val_loss: 85.5260\n",
            "Epoch 35/250\n",
            " - 0s - loss: 8.6687 - val_loss: 90.7455\n",
            "Epoch 36/250\n",
            " - 0s - loss: 8.5014 - val_loss: 88.4411\n",
            "Epoch 37/250\n",
            " - 0s - loss: 8.6539 - val_loss: 93.1578\n",
            "Epoch 38/250\n",
            " - 0s - loss: 8.8157 - val_loss: 85.6469\n",
            "Epoch 39/250\n",
            " - 0s - loss: 8.8705 - val_loss: 87.2155\n",
            "Epoch 40/250\n",
            " - 0s - loss: 8.8621 - val_loss: 87.3131\n",
            "Epoch 41/250\n",
            " - 0s - loss: 8.5229 - val_loss: 90.3983\n",
            "Epoch 42/250\n",
            " - 0s - loss: 8.8943 - val_loss: 88.1694\n",
            "Epoch 43/250\n",
            " - 0s - loss: 8.4399 - val_loss: 90.7904\n",
            "Epoch 44/250\n",
            " - 0s - loss: 8.8564 - val_loss: 99.7659\n",
            "Epoch 45/250\n",
            " - 0s - loss: 9.4974 - val_loss: 97.2337\n",
            "Epoch 46/250\n",
            " - 0s - loss: 8.5832 - val_loss: 89.5145\n",
            "Epoch 47/250\n",
            " - 0s - loss: 8.3271 - val_loss: 94.5673\n",
            "Epoch 48/250\n",
            " - 0s - loss: 8.9029 - val_loss: 90.3247\n",
            "Epoch 49/250\n",
            " - 0s - loss: 8.6419 - val_loss: 86.6143\n",
            "Epoch 50/250\n",
            " - 0s - loss: 8.7203 - val_loss: 91.4120\n",
            "Epoch 51/250\n",
            " - 0s - loss: 8.8397 - val_loss: 89.5637\n",
            "Epoch 52/250\n",
            " - 0s - loss: 8.5416 - val_loss: 89.7588\n",
            "Epoch 53/250\n",
            " - 0s - loss: 8.7095 - val_loss: 84.8395\n",
            "Epoch 54/250\n",
            " - 0s - loss: 8.4968 - val_loss: 92.1821\n",
            "Epoch 55/250\n",
            " - 0s - loss: 8.7322 - val_loss: 95.7551\n",
            "Epoch 56/250\n",
            " - 0s - loss: 9.6011 - val_loss: 91.1941\n",
            "Epoch 57/250\n",
            " - 0s - loss: 9.2462 - val_loss: 88.1327\n",
            "Epoch 58/250\n",
            " - 0s - loss: 8.7508 - val_loss: 88.3045\n",
            "Epoch 59/250\n",
            " - 0s - loss: 8.3517 - val_loss: 91.6909\n",
            "Epoch 60/250\n",
            " - 0s - loss: 8.5938 - val_loss: 82.1669\n",
            "Epoch 61/250\n",
            " - 0s - loss: 8.5590 - val_loss: 92.0894\n",
            "Epoch 62/250\n",
            " - 0s - loss: 8.6847 - val_loss: 89.1908\n",
            "Epoch 63/250\n",
            " - 0s - loss: 8.3724 - val_loss: 91.1499\n",
            "Epoch 64/250\n",
            " - 0s - loss: 8.6414 - val_loss: 92.7538\n",
            "Epoch 65/250\n",
            " - 0s - loss: 8.6709 - val_loss: 95.6195\n",
            "Epoch 66/250\n",
            " - 0s - loss: 8.7423 - val_loss: 87.1226\n",
            "Epoch 67/250\n",
            " - 0s - loss: 8.4225 - val_loss: 93.7265\n",
            "Epoch 68/250\n",
            " - 0s - loss: 8.9700 - val_loss: 92.8446\n",
            "Epoch 69/250\n",
            " - 0s - loss: 8.4987 - val_loss: 85.9628\n",
            "Epoch 70/250\n",
            " - 0s - loss: 8.2645 - val_loss: 86.0974\n",
            "Epoch 71/250\n",
            " - 0s - loss: 8.2403 - val_loss: 90.8046\n",
            "Epoch 72/250\n",
            " - 0s - loss: 8.4047 - val_loss: 88.6759\n",
            "Epoch 73/250\n",
            " - 0s - loss: 8.2852 - val_loss: 98.3046\n",
            "Epoch 74/250\n",
            " - 0s - loss: 8.3128 - val_loss: 88.5511\n",
            "Epoch 75/250\n",
            " - 0s - loss: 8.3107 - val_loss: 85.3921\n",
            "Epoch 76/250\n",
            " - 0s - loss: 8.5778 - val_loss: 89.4586\n",
            "Epoch 77/250\n",
            " - 0s - loss: 8.4424 - val_loss: 89.2292\n",
            "Epoch 78/250\n",
            " - 0s - loss: 8.1735 - val_loss: 89.0440\n",
            "Epoch 79/250\n",
            " - 0s - loss: 8.2630 - val_loss: 90.8661\n",
            "Epoch 80/250\n",
            " - 0s - loss: 8.4006 - val_loss: 82.9330\n",
            "Epoch 81/250\n",
            " - 0s - loss: 8.2327 - val_loss: 92.1673\n",
            "Epoch 82/250\n",
            " - 0s - loss: 8.2582 - val_loss: 91.2212\n",
            "Epoch 83/250\n",
            " - 0s - loss: 8.2267 - val_loss: 96.3422\n",
            "Epoch 84/250\n",
            " - 0s - loss: 8.1902 - val_loss: 90.9783\n",
            "Epoch 85/250\n",
            " - 0s - loss: 8.2375 - val_loss: 87.6240\n",
            "Epoch 86/250\n",
            " - 0s - loss: 8.1304 - val_loss: 92.0507\n",
            "Epoch 87/250\n",
            " - 0s - loss: 8.0415 - val_loss: 84.9851\n",
            "Epoch 88/250\n",
            " - 0s - loss: 8.3973 - val_loss: 88.7333\n",
            "Epoch 89/250\n",
            " - 0s - loss: 8.8912 - val_loss: 98.9192\n",
            "Epoch 90/250\n",
            " - 0s - loss: 8.9112 - val_loss: 98.8854\n",
            "Epoch 91/250\n",
            " - 0s - loss: 8.6726 - val_loss: 89.1641\n",
            "Epoch 92/250\n",
            " - 0s - loss: 8.1866 - val_loss: 88.1380\n",
            "Epoch 93/250\n",
            " - 0s - loss: 8.6315 - val_loss: 95.0583\n",
            "Epoch 94/250\n",
            " - 0s - loss: 8.4067 - val_loss: 93.6770\n",
            "Epoch 95/250\n",
            " - 0s - loss: 8.3767 - val_loss: 86.9085\n",
            "Epoch 96/250\n",
            " - 0s - loss: 9.6658 - val_loss: 98.0323\n",
            "Epoch 97/250\n",
            " - 0s - loss: 8.7205 - val_loss: 90.3424\n",
            "Epoch 98/250\n",
            " - 0s - loss: 8.1929 - val_loss: 92.7441\n",
            "Epoch 99/250\n",
            " - 0s - loss: 8.5548 - val_loss: 85.3842\n",
            "Epoch 100/250\n",
            " - 0s - loss: 8.1555 - val_loss: 93.9532\n",
            "Epoch 101/250\n",
            " - 0s - loss: 8.2035 - val_loss: 85.8061\n",
            "Epoch 102/250\n",
            " - 0s - loss: 8.6671 - val_loss: 92.6997\n",
            "Epoch 103/250\n",
            " - 0s - loss: 8.2878 - val_loss: 89.5329\n",
            "Epoch 104/250\n",
            " - 0s - loss: 8.7651 - val_loss: 102.5899\n",
            "Epoch 105/250\n",
            " - 0s - loss: 8.5378 - val_loss: 85.0812\n",
            "Epoch 106/250\n",
            " - 0s - loss: 8.2370 - val_loss: 87.2342\n",
            "Epoch 107/250\n",
            " - 0s - loss: 8.1250 - val_loss: 96.7275\n",
            "Epoch 108/250\n",
            " - 0s - loss: 7.9462 - val_loss: 88.7239\n",
            "Epoch 109/250\n",
            " - 0s - loss: 8.3054 - val_loss: 99.7614\n",
            "Epoch 110/250\n",
            " - 0s - loss: 8.3825 - val_loss: 92.1589\n",
            "Epoch 111/250\n",
            " - 0s - loss: 7.9448 - val_loss: 91.4265\n",
            "Epoch 112/250\n",
            " - 0s - loss: 8.0496 - val_loss: 90.7881\n",
            "Epoch 113/250\n",
            " - 0s - loss: 7.8778 - val_loss: 96.7611\n",
            "Epoch 114/250\n",
            " - 0s - loss: 7.9924 - val_loss: 92.1027\n",
            "Epoch 115/250\n",
            " - 0s - loss: 8.4053 - val_loss: 92.8440\n",
            "Epoch 116/250\n",
            " - 0s - loss: 7.9855 - val_loss: 93.6165\n",
            "Epoch 117/250\n",
            " - 0s - loss: 8.1018 - val_loss: 90.2390\n",
            "Epoch 118/250\n",
            " - 0s - loss: 8.1275 - val_loss: 89.7975\n",
            "Epoch 119/250\n",
            " - 0s - loss: 7.8263 - val_loss: 93.3613\n",
            "Epoch 120/250\n",
            " - 0s - loss: 8.1206 - val_loss: 95.1958\n",
            "Epoch 121/250\n",
            " - 0s - loss: 7.9710 - val_loss: 84.7547\n",
            "Epoch 122/250\n",
            " - 0s - loss: 8.3680 - val_loss: 88.6801\n",
            "Epoch 123/250\n",
            " - 0s - loss: 8.3002 - val_loss: 102.5112\n",
            "Epoch 124/250\n",
            " - 0s - loss: 8.3054 - val_loss: 92.3338\n",
            "Epoch 125/250\n",
            " - 0s - loss: 8.0464 - val_loss: 91.3602\n",
            "Epoch 126/250\n",
            " - 0s - loss: 8.2818 - val_loss: 91.2273\n",
            "Epoch 127/250\n",
            " - 0s - loss: 7.9761 - val_loss: 97.6232\n",
            "Epoch 128/250\n",
            " - 0s - loss: 8.1317 - val_loss: 94.8606\n",
            "Epoch 129/250\n",
            " - 0s - loss: 8.1602 - val_loss: 94.2729\n",
            "Epoch 130/250\n",
            " - 0s - loss: 7.9643 - val_loss: 91.2411\n",
            "Epoch 131/250\n",
            " - 0s - loss: 7.8769 - val_loss: 95.4205\n",
            "Epoch 132/250\n",
            " - 0s - loss: 8.0091 - val_loss: 87.4310\n",
            "Epoch 133/250\n",
            " - 0s - loss: 7.9310 - val_loss: 90.4476\n",
            "Epoch 134/250\n",
            " - 0s - loss: 8.0851 - val_loss: 91.7158\n",
            "Epoch 135/250\n",
            " - 0s - loss: 8.1850 - val_loss: 97.6416\n",
            "Epoch 136/250\n",
            " - 0s - loss: 7.7996 - val_loss: 92.2050\n",
            "Epoch 137/250\n",
            " - 0s - loss: 7.9583 - val_loss: 95.5990\n",
            "Epoch 138/250\n",
            " - 0s - loss: 7.9114 - val_loss: 85.3515\n",
            "Epoch 139/250\n",
            " - 0s - loss: 7.7755 - val_loss: 97.5104\n",
            "Epoch 140/250\n",
            " - 0s - loss: 7.9973 - val_loss: 94.1197\n",
            "Epoch 141/250\n",
            " - 0s - loss: 8.3782 - val_loss: 91.1840\n",
            "Epoch 142/250\n",
            " - 0s - loss: 8.6765 - val_loss: 91.2530\n",
            "Epoch 143/250\n",
            " - 0s - loss: 8.3694 - val_loss: 91.7080\n",
            "Epoch 144/250\n",
            " - 0s - loss: 8.1369 - val_loss: 90.5467\n",
            "Epoch 145/250\n",
            " - 0s - loss: 8.3147 - val_loss: 92.4000\n",
            "Epoch 146/250\n",
            " - 0s - loss: 8.2231 - val_loss: 101.5456\n",
            "Epoch 147/250\n",
            " - 0s - loss: 8.4527 - val_loss: 95.5203\n",
            "Epoch 148/250\n",
            " - 0s - loss: 7.6692 - val_loss: 91.0580\n",
            "Epoch 149/250\n",
            " - 0s - loss: 8.2211 - val_loss: 94.2041\n",
            "Epoch 150/250\n",
            " - 0s - loss: 8.1661 - val_loss: 93.1510\n",
            "Epoch 151/250\n",
            " - 0s - loss: 8.0961 - val_loss: 101.1698\n",
            "Epoch 152/250\n",
            " - 0s - loss: 7.9555 - val_loss: 90.1383\n",
            "Epoch 153/250\n",
            " - 0s - loss: 7.7896 - val_loss: 91.0560\n",
            "Epoch 154/250\n",
            " - 0s - loss: 7.8392 - val_loss: 91.0581\n",
            "Epoch 155/250\n",
            " - 0s - loss: 7.8260 - val_loss: 98.5685\n",
            "Epoch 156/250\n",
            " - 0s - loss: 8.2505 - val_loss: 94.9892\n",
            "Epoch 157/250\n",
            " - 0s - loss: 8.1294 - val_loss: 94.9028\n",
            "Epoch 158/250\n",
            " - 0s - loss: 8.2276 - val_loss: 96.1654\n",
            "Epoch 159/250\n",
            " - 0s - loss: 8.1030 - val_loss: 97.1784\n",
            "Epoch 160/250\n",
            " - 0s - loss: 7.7322 - val_loss: 95.1718\n",
            "Epoch 161/250\n",
            " - 0s - loss: 7.8397 - val_loss: 91.8253\n",
            "Epoch 162/250\n",
            " - 0s - loss: 7.7456 - val_loss: 92.7384\n",
            "Epoch 163/250\n",
            " - 0s - loss: 8.1680 - val_loss: 91.8017\n",
            "Epoch 164/250\n",
            " - 0s - loss: 8.1869 - val_loss: 100.3125\n",
            "Epoch 165/250\n",
            " - 0s - loss: 8.2561 - val_loss: 93.6175\n",
            "Epoch 166/250\n",
            " - 0s - loss: 7.7012 - val_loss: 94.4884\n",
            "Epoch 167/250\n",
            " - 0s - loss: 7.5860 - val_loss: 97.0485\n",
            "Epoch 168/250\n",
            " - 0s - loss: 7.8369 - val_loss: 97.6340\n",
            "Epoch 169/250\n",
            " - 0s - loss: 8.1946 - val_loss: 101.1514\n",
            "Epoch 170/250\n",
            " - 0s - loss: 8.4486 - val_loss: 95.3559\n",
            "Epoch 171/250\n",
            " - 0s - loss: 8.0475 - val_loss: 88.1587\n",
            "Epoch 172/250\n",
            " - 0s - loss: 8.3466 - val_loss: 106.9643\n",
            "Epoch 173/250\n",
            " - 0s - loss: 8.8561 - val_loss: 87.8907\n",
            "Epoch 174/250\n",
            " - 0s - loss: 8.1332 - val_loss: 90.2952\n",
            "Epoch 175/250\n",
            " - 0s - loss: 7.8945 - val_loss: 98.0197\n",
            "Epoch 176/250\n",
            " - 0s - loss: 7.7405 - val_loss: 94.4045\n",
            "Epoch 177/250\n",
            " - 0s - loss: 7.7279 - val_loss: 98.0570\n",
            "Epoch 178/250\n",
            " - 0s - loss: 8.4087 - val_loss: 92.1493\n",
            "Epoch 179/250\n",
            " - 0s - loss: 7.8770 - val_loss: 93.7533\n",
            "Epoch 180/250\n",
            " - 0s - loss: 7.7500 - val_loss: 97.1908\n",
            "Epoch 181/250\n",
            " - 0s - loss: 7.9060 - val_loss: 92.2954\n",
            "Epoch 182/250\n",
            " - 0s - loss: 7.5433 - val_loss: 93.9630\n",
            "Epoch 183/250\n",
            " - 0s - loss: 7.7897 - val_loss: 95.3046\n",
            "Epoch 184/250\n",
            " - 0s - loss: 8.0083 - val_loss: 98.8533\n",
            "Epoch 185/250\n",
            " - 0s - loss: 8.2112 - val_loss: 93.7977\n",
            "Epoch 186/250\n",
            " - 0s - loss: 7.8093 - val_loss: 100.7695\n",
            "Epoch 187/250\n",
            " - 0s - loss: 7.9009 - val_loss: 93.7372\n",
            "Epoch 188/250\n",
            " - 0s - loss: 8.2122 - val_loss: 92.3871\n",
            "Epoch 189/250\n",
            " - 0s - loss: 8.4785 - val_loss: 98.8921\n",
            "Epoch 190/250\n",
            " - 0s - loss: 8.0771 - val_loss: 88.0967\n",
            "Epoch 191/250\n",
            " - 0s - loss: 7.7153 - val_loss: 99.7631\n",
            "Epoch 192/250\n",
            " - 0s - loss: 7.6604 - val_loss: 94.8382\n",
            "Epoch 193/250\n",
            " - 0s - loss: 8.4026 - val_loss: 97.3240\n",
            "Epoch 194/250\n",
            " - 0s - loss: 8.1378 - val_loss: 102.6466\n",
            "Epoch 195/250\n",
            " - 0s - loss: 7.9649 - val_loss: 90.6784\n",
            "Epoch 196/250\n",
            " - 0s - loss: 8.0714 - val_loss: 89.7004\n",
            "Epoch 197/250\n",
            " - 0s - loss: 7.8155 - val_loss: 96.8392\n",
            "Epoch 198/250\n",
            " - 0s - loss: 7.6207 - val_loss: 90.6315\n",
            "Epoch 199/250\n",
            " - 0s - loss: 7.7655 - val_loss: 96.0527\n",
            "Epoch 200/250\n",
            " - 0s - loss: 7.7747 - val_loss: 101.9848\n",
            "Epoch 201/250\n",
            " - 0s - loss: 7.8121 - val_loss: 90.8101\n",
            "Epoch 202/250\n",
            " - 0s - loss: 7.9982 - val_loss: 105.8674\n",
            "Epoch 203/250\n",
            " - 0s - loss: 8.4142 - val_loss: 87.2576\n",
            "Epoch 204/250\n",
            " - 0s - loss: 8.1197 - val_loss: 95.6363\n",
            "Epoch 205/250\n",
            " - 0s - loss: 7.8083 - val_loss: 91.0212\n",
            "Epoch 206/250\n",
            " - 0s - loss: 7.8702 - val_loss: 98.9743\n",
            "Epoch 207/250\n",
            " - 0s - loss: 7.6165 - val_loss: 93.9203\n",
            "Epoch 208/250\n",
            " - 0s - loss: 7.2652 - val_loss: 94.5972\n",
            "Epoch 209/250\n",
            " - 0s - loss: 8.1486 - val_loss: 105.2103\n",
            "Epoch 210/250\n",
            " - 0s - loss: 8.3776 - val_loss: 101.1311\n",
            "Epoch 211/250\n",
            " - 0s - loss: 7.7667 - val_loss: 101.1502\n",
            "Epoch 212/250\n",
            " - 0s - loss: 8.4706 - val_loss: 92.0705\n",
            "Epoch 213/250\n",
            " - 0s - loss: 8.9869 - val_loss: 96.0536\n",
            "Epoch 214/250\n",
            " - 0s - loss: 8.1761 - val_loss: 96.6550\n",
            "Epoch 215/250\n",
            " - 0s - loss: 7.8119 - val_loss: 92.8228\n",
            "Epoch 216/250\n",
            " - 0s - loss: 7.7193 - val_loss: 97.5437\n",
            "Epoch 217/250\n",
            " - 0s - loss: 7.6520 - val_loss: 90.4787\n",
            "Epoch 218/250\n",
            " - 0s - loss: 7.8623 - val_loss: 99.3301\n",
            "Epoch 219/250\n",
            " - 0s - loss: 7.8470 - val_loss: 100.4612\n",
            "Epoch 220/250\n",
            " - 0s - loss: 7.9214 - val_loss: 95.4388\n",
            "Epoch 221/250\n",
            " - 0s - loss: 7.6926 - val_loss: 94.6241\n",
            "Epoch 222/250\n",
            " - 0s - loss: 7.6171 - val_loss: 104.1498\n",
            "Epoch 223/250\n",
            " - 0s - loss: 7.4632 - val_loss: 89.7900\n",
            "Epoch 224/250\n",
            " - 0s - loss: 7.4347 - val_loss: 94.0318\n",
            "Epoch 225/250\n",
            " - 0s - loss: 7.6740 - val_loss: 93.6342\n",
            "Epoch 226/250\n",
            " - 0s - loss: 7.6950 - val_loss: 100.9735\n",
            "Epoch 227/250\n",
            " - 0s - loss: 8.3514 - val_loss: 91.8098\n",
            "Epoch 228/250\n",
            " - 0s - loss: 7.8768 - val_loss: 94.1171\n",
            "Epoch 229/250\n",
            " - 0s - loss: 8.0126 - val_loss: 101.3475\n",
            "Epoch 230/250\n",
            " - 0s - loss: 7.5160 - val_loss: 100.7363\n",
            "Epoch 231/250\n",
            " - 0s - loss: 7.4933 - val_loss: 92.8224\n",
            "Epoch 232/250\n",
            " - 0s - loss: 8.0551 - val_loss: 92.5841\n",
            "Epoch 233/250\n",
            " - 0s - loss: 7.6909 - val_loss: 93.6098\n",
            "Epoch 234/250\n",
            " - 0s - loss: 7.6120 - val_loss: 100.9698\n",
            "Epoch 235/250\n",
            " - 0s - loss: 7.4321 - val_loss: 91.0680\n",
            "Epoch 236/250\n",
            " - 0s - loss: 7.3022 - val_loss: 99.0285\n",
            "Epoch 237/250\n",
            " - 0s - loss: 7.7384 - val_loss: 91.1814\n",
            "Epoch 238/250\n",
            " - 0s - loss: 7.3706 - val_loss: 95.7542\n",
            "Epoch 239/250\n",
            " - 0s - loss: 7.4136 - val_loss: 98.5153\n",
            "Epoch 240/250\n",
            " - 0s - loss: 7.5090 - val_loss: 100.1920\n",
            "Epoch 241/250\n",
            " - 0s - loss: 7.6913 - val_loss: 95.8272\n",
            "Epoch 242/250\n",
            " - 0s - loss: 7.3328 - val_loss: 93.0214\n",
            "Epoch 243/250\n",
            " - 0s - loss: 7.6185 - val_loss: 93.2069\n",
            "Epoch 244/250\n",
            " - 0s - loss: 7.5717 - val_loss: 97.7432\n",
            "Epoch 245/250\n",
            " - 0s - loss: 7.7464 - val_loss: 97.9860\n",
            "Epoch 246/250\n",
            " - 0s - loss: 7.4377 - val_loss: 101.3220\n",
            "Epoch 247/250\n",
            " - 0s - loss: 7.3692 - val_loss: 96.4809\n",
            "Epoch 248/250\n",
            " - 0s - loss: 7.6808 - val_loss: 99.2413\n",
            "Epoch 249/250\n",
            " - 0s - loss: 7.7666 - val_loss: 93.9799\n",
            "Epoch 250/250\n",
            " - 0s - loss: 7.7257 - val_loss: 90.6185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa9accc4ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}